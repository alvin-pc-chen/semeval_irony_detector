{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "I use glove embeddings to build an irony detector for tweets\n",
    "\n",
    "Data comes from: https://github.com/Cyvhee/SemEval2018-Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO:\\n6. Can use random forests to prevent overfitting?\\n7. Do writeup: introduction, code explanation at each cell, results\\n- write util.py descriptions\\n- add baseline?\\n8. Commit #1\\n- change training data, glove embeddings, hyperparameters\\n- download on pc and try to run on gpu\\n-  Run model until good f1 then save\\n- Commit #2\\n9. Figure out how to add try out\\n10. Build try out shell\\n- Final Commit\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "- change training data, glove embeddings, hyperparameters\n",
    "- download on pc and try to run on gpu\n",
    "- Run model until good f1 then save\n",
    "- Commit #2\n",
    "- Can use random forests to prevent overfitting?\n",
    "- add baseline?\n",
    "- Writeup: key skills demonstrated, intro to task, testing results\n",
    "- Commit #3\n",
    "- Figure out how to add try out\n",
    "- Build try out shell\n",
    "- Final Commit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract embeddings\n",
    "\n",
    "# ! wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "# ! unzip glove.twitter.27B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "embeddings_path = 'glove.twitter.27B.25d.txt'\n",
    "vocab_path = \"./vocab.txt\"\n",
    "SPECIAL_TOKENS = ['<UNK>', '<PAD>', '<SOS>', '<EOS>']\n",
    "\n",
    "# Download and split data\n",
    "train_sentences, train_labels, test_sentences, test_labels, label2i = util.load_datasets()\n",
    "training_sentences, training_labels, dev_sentences, dev_labels = util.split_data(train_sentences, train_labels, split=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tokenizer and make vocab\n",
    "tokenizer = util.Tokenizer()\n",
    "all_data = train_sentences + test_sentences\n",
    "tokenized_data = tokenizer.tokenize(all_data)\n",
    "# vocab = sorted(set([w for ws in tokenized_data + [SPECIAL_TOKENS] for w in ws]))\n",
    "# with open('vocab.txt', 'w') as vf:\n",
    "#     vf.write('\\n'.join(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embeddings from glove.twitter.27B.25d.txt...\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained embeddings, find the out-of-vocabularies, and add to word2i and embeddings\n",
    "glove_word2i, glove_embeddings = util.get_glove_embeddings(embeddings_path)\n",
    "oovs = util.get_oovs(vocab_path, glove_word2i)\n",
    "word2i, embeddings = util.update_embeddings(glove_word2i, glove_embeddings, oovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "import torch\n",
    "\n",
    "model = util.IronyDetector(\n",
    "    input_dim=embeddings.shape[1],\n",
    "    hidden_dim=8,\n",
    "    embeddings_tensor=embeddings,\n",
    "    pad_idx=word2i[\"<PAD>\"],\n",
    "    output_size=len(label2i),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "learning_rate = 0.00005\n",
    "weight_decay = 0\n",
    "optimizer = torch.optim.AdamW(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Create batches\n",
    "batch_tokenized = []\n",
    "for batch in util.make_batches(training_sentences, batch_size):\n",
    "    batch_tokenized.append(tokenizer(batch))\n",
    "batch_labels = util.make_batches(training_labels, batch_size)\n",
    "dev_sentences = tokenizer(dev_sentences)\n",
    "test_sentences = tokenizer(test_sentences)\n",
    "\n",
    "# Encode data\n",
    "train_features = [util.encode_sentences(batch, word2i) for batch in batch_tokenized]\n",
    "train_labels = [util.encode_labels(batch) for batch in batch_labels]\n",
    "dev_features = util.encode_sentences(dev_sentences, word2i)\n",
    "dev_labels = [int(l) for l in dev_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8293c2549cc241409be06af47d6cbd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.6955968020301239\n",
      "Evaluating dev...\n",
      "Dev F1 0.6350710900473934\n",
      "Avg Dev F1 0.3175355450236967\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trained_model = util.training_loop(\n",
    "    epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "    label2i,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 0.5680365296803653\n",
      "Avg Test F1 0.28401826484018267\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test_features = util.encode_sentences(test_sentences, word2i)\n",
    "test_labels = [int(l) for l in test_labels]\n",
    "preds = util.predict(trained_model, test_features)\n",
    "dev_f1 = util.f1_score(preds, test_labels, label2i['1'])\n",
    "dev_avg_f1 = util.avg_f1_score(preds, test_labels, set(label2i.values()))\n",
    "print(f\"Test F1 {dev_f1}\")\n",
    "print(f\"Avg Test F1 {dev_avg_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model at: /Users/alvinchen/Documents/GitHub/semeval_irony_detector/pretrained_model/\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "util.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irony",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
